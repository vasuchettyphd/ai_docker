[tool.poetry]
name = "llama3-model-server"
version = "0.1.0"
description = "Flask API for quantized LLaMA 3"
authors = ["You <you@example.com>"]
package-mode = false 

[tool.poetry.dependencies]
python = "^3.10"
flask = "*"
torch = { url = "https://download.pytorch.org/whl/cu121/torch-2.3.0%2Bcu121-cp310-cp310-linux_x86_64.whl" }
torchvision = "*"
torchaudio = "*"
transformers = "*"
accelerate = "*"
bitsandbytes = "*"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"